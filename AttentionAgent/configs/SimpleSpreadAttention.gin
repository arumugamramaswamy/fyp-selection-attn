import algorithms.cma
import misc.utility
import solutions.torch_solutions
import tasks.gym_task


# CMA configurations
cma.CMA.population_size = 256
cma.CMA.init_sigma = 0.1

cma.CMAMaster.seed = 0
cma.CMAMaster.n_repeat = 16
cma.CMAMaster.max_iter = 2000
cma.CMAMaster.eval_every_n_iter = 10
cma.CMAMaster.n_eval_roll_outs = 4

utility.get_es_master.es_algorithm = @cma.CMAMaster
utility.get_es_worker.es_algorithm = @cma.CMAWorker


# Solution configurations
torch_solutions.AttentionSolution.output_dim = 5
# torch_solutions.AttentionSolution.query_dim = 2
torch_solutions.AttentionSolution.embedding_dim = 16
torch_solutions.AttentionSolution.output_activation = "softmax"
torch_solutions.AttentionSolution.num_hiddens = []
torch_solutions.AttentionSolution.l2_coefficient = 0
torch_solutions.AttentionSolution.data_dim = 4
torch_solutions.AttentionSolution.activation = "tanh"
# torch_solutions.AttentionSolution.checkpoint_path = "log/model_2000.npz"

utility.create_solution.solution_loader = @torch_solutions.AttentionSolution()


# Task configurations
utility.create_task.out_of_track_cap = 20
utility.create_task.max_steps = 1000
utility.create_task.task_loader = @gym_task.SimpleSpreadTask()
